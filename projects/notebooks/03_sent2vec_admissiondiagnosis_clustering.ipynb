{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sent2Vec: admission diagnosis clustering\n",
    "\n",
    "Group diagnosis with feature vectors from pretrained NLP model\n",
    "\n",
    "CODE NOT RUNNING YET, STILL BUGGY WITH THE \"embed_sentences\" function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate feature vector for each diagnosis string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sent2vec\n",
    "\n",
    "os.makedirs(\"_cache\", exist_ok=True)\n",
    "\n",
    "SENT2VEC_MODEL_PATH = '/data/wiki_unigrams.bin'\n",
    "sent2vec_model = sent2vec.Sent2vecModel()\n",
    "\n",
    "assert os.path.exists(SENT2VEC_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_demo_dict = np.load('_cache/patient_demo.npy', allow_pickle=True).item()\n",
    "admissiondx = patient_demo_dict['apacheadmissiondx']\n",
    "\n",
    "admissiondx_embs_cache_path = '_cache/admissiondx_embs.npy'\n",
    "if os.path.exists(admissiondx_embs_cache_path):\n",
    "    admissiondx_embs = np.load(admissiondx_embs_cache_path, allow_pickle=True)\n",
    "\n",
    "else:\n",
    "    sent2vec_model.load_model(SENT2VEC_MODEL_PATH, inference_mode=True)\n",
    "    admissiondx_embs = sent2vec_model.embed_sentences(admissiondx)\n",
    "    np.save('_cache/admissiondx_embs.npy', admissiondx_embs)\n",
    "    sent2vec_model.release_shared_mem(SENT2VEC_MODEL_PATH)\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/chen/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1001312534/out/client/extension.js:52:301180)",
      "at w.execute (/home/chen/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1001312534/out/client/extension.js:52:300551)",
      "at w.start (/home/chen/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1001312534/out/client/extension.js:52:296215)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/chen/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1001312534/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/home/chen/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1001312534/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "admissiondx_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissiondx_embs = admissiondx_embs.reshape(admissiondx_embs.shape[0], -1)\n",
    "admissiondx_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature vector clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import LatentDirichletAllocation, PCA\n",
    "from sklearn.cluster import AffinityPropagation, DBSCAN, OPTICS\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster\n",
    "DBSCAN_clusters = DBSCAN(eps=0.3, min_samples=10)\n",
    "DBSCAN_clusters.fit(admissiondx_embs)\n",
    "print(\"Number of core samples:\", DBSCAN_clusters.core_sample_indices_.shape)\n",
    "\n",
    "admissiondx_dbscan_labels = DBSCAN_clusters.labels_\n",
    "core_samples_mask = np.zeros_like(admissiondx_dbscan_labels, dtype=bool)\n",
    "core_samples_mask[DBSCAN_clusters.core_sample_indices_] = True\n",
    "\n",
    "n_clusters_ = len(set(admissiondx_dbscan_labels)) - (1 if -1 in admissiondx_dbscan_labels else 0)\n",
    "n_noise_ = list(admissiondx_dbscan_labels).count(-1)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_dict = {}\n",
    "\n",
    "for i, label in enumerate(admissiondx_dbscan_labels):\n",
    "    if label in diagnosis_dict:\n",
    "        diagnosis_dict[label].append(i)\n",
    "    else:\n",
    "        diagnosis_dict[label] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissiondx[diagnosis_dict[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissiondx[diagnosis_dict[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(128):\n",
    "    print('\\n',len(admissiondx[diagnosis_dict[i]]), '\\n', admissiondx[diagnosis_dict[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTICS Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTICS_cluster = OPTICS(min_samples=50, xi=.05, min_cluster_size=.01)\n",
    "OPTICS_cluster.fit(admissiondx_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels_optics = len(set(OPTICS_cluster.labels_))\n",
    "print('Estimated number of labels: %d' % num_labels_optics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_dict_optics = {}\n",
    "\n",
    "for i, label in enumerate(OPTICS_cluster.labels_):\n",
    "    if label in diagnosis_dict_optics:\n",
    "        diagnosis_dict_optics[label].append(i)\n",
    "    else:\n",
    "        diagnosis_dict_optics[label] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('diagnosis_stats.txt', 'w')\n",
    "\n",
    "# for i in range(-1, 19):\n",
    "#     f.write(f'Group {i}\\n')\n",
    "#     c = Counter(admissiondx[diagnosis_dict_optics[i]])\n",
    "#     for key in c:\n",
    "#         f.write(f'{key}: {c[key]}\\n')\n",
    "#     f.write('\\n\\n\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save clustering models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(OPTICS_cluster, 'admission_diagnosis_cluster_OPTICS')\n",
    "joblib.dump(DBSCAN_clusters, 'admission_diagnosis_cluster_DBSCAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTICS_cluster = joblib.load('admission_diagnosis_cluster_OPTICS')\n",
    "DBSCAN_clusters = joblib.load('admission_diagnosis_cluster_DBSCAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissiondx_dbscan_labels = DBSCAN_clusters.labels_\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(admissiondx_dbscan_labels))]\n",
    "for k, col in zip(admissiondx_dbscan_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (admissiondx_dbscan_labels == k)\n",
    "\n",
    "    xy = admissiondx_embs[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = admissiondx_embs[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
