{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from projects.data_cleaning.common import *\n",
    "from projects.data_cleaning.utils.data_io import *\n",
    "from projects.data_cleaning.utils.utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_mapping = pd.read_csv('processed/DatasetOverview - Inputs.tsv', sep='\\t', header=0)\n",
    "pid_diagnosis = np.load('processed/patient_grouped_by_diagnosis.npy', allow_pickle=True).item()\n",
    "pid_infarction = pid_diagnosis['Infarction, acute myocardial (MI)']\n",
    "pid_acute_renal_failure = np.load('processed/acute_renal_failure_cases_valid.npy')\n",
    "pid_total = np.load('processed/patient_ids_all.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "table_dict = data_mapping[['TableID', 'TableSource']]\n",
    "table_dict = table_dict.drop_duplicates()\n",
    "table_dict = {table_dict.iloc[i,0]:table_dict.iloc[i,1] for i in range(table_dict.shape[0])}\n",
    "\n",
    "uid_dict = data_mapping[['ParamNameOrigin', 'TableUID']]\n",
    "uid_dict = {uid_dict.iloc[i,0]:uid_dict.iloc[i,1] for i in range(uid_dict.shape[0])}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def convert_lab_data_to_num(lab_data):\n",
    "    data_num = []\n",
    "    for d in lab_data:\n",
    "        if o == '':\n",
    "            continue\n",
    "        elif '<' in o:\n",
    "            data_num.append(float(o.replace('<', '')))\n",
    "        elif '>' in o:\n",
    "            data_num.append(float(o.replace('>', '')))\n",
    "        elif '%' in o:\n",
    "            data_num.append(float(o.replace('%', '')))\n",
    "    return data_num"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "drugrate_unit_dict = {\n",
    "    'mcg/min': 1/1000,\n",
    "    'mcg/hr': 1/60/1000,\n",
    "    'mcg/kg/min': 1/1000,\n",
    "    'mcg/kg/hr': 1/60/1000,\n",
    "    \n",
    "    'mg/min': 1/1000,\n",
    "    'mg/hr': 1/60/1000,\n",
    "    'mg/kg/min': 1/1000,\n",
    "    'mg/kg/hr': 1/60/1000,\n",
    "    \n",
    "    'units/min': 1,\n",
    "    'units/hr': 1/60,\n",
    "    \n",
    "    'ml/min': 1,\n",
    "    'ml/hr':1/60,\n",
    "}\n",
    "\n",
    "\n",
    "def unify_drugrate_unit(rate, name, weight):\n",
    "    convert_coeff = 1\n",
    "    for i in range(len(weight)):\n",
    "        if weight[i] == '':\n",
    "            weight[i] = 1\n",
    "        else:\n",
    "            weight[i] = float(weight[i])\n",
    "                \n",
    "    for k in drugrate_unit_dict:\n",
    "        if k in name: \n",
    "            convert_coeff = drugrate_unit_dict[k]\n",
    "    \n",
    "    return rate.astype(float) * weight * convert_coeff"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save patient data in .CSV file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "for pid in pid_total:\n",
    "    data = load_patient_data_by_id(pid)\n",
    "    \n",
    "    data_table = {\n",
    "        'Offset': np.array([]),\n",
    "        'UID': np.array([]),\n",
    "        'Value': np.array([]),\n",
    "        'Unit': np.array([]),\n",
    "    }\n",
    "    \n",
    "    patient_info = {\n",
    "        'UID': np.array([]),\n",
    "        'Value': np.array([]),\n",
    "    }\n",
    "    \n",
    "    for table_id in table_dict.keys():\n",
    "        # patient information\n",
    "        if table_id == 0:\n",
    "            entry_mapping = data_mapping[data_mapping['TableID']==table_id]\n",
    "            table_source = table_dict[table_id]\n",
    "            for _, entry in entry_mapping.iterrows():\n",
    "                entry_name_eicu = entry['ParamNameOrigin']\n",
    "                entry_uid = entry['TableUID']\n",
    "                entry_value = data[table_source][entry_name_eicu][0]\n",
    "\n",
    "                patient_info['UID'] = np.append(patient_info['UID'], entry_uid)\n",
    "                patient_info['Value'] = np.append(patient_info['Value'], entry_value)\n",
    "\n",
    "        \n",
    "        # periodic and aperiodic vitals\n",
    "        elif table_id in [1,2]:\n",
    "            \n",
    "            # read and sort data\n",
    "            entry_mapping = data_mapping[data_mapping['TableID']==table_id]\n",
    "            table_source = table_dict[table_id]\n",
    "\n",
    "            sorted_ids = np.argsort(data[table_source]['observationoffset'])\n",
    "            sorted_offset = np.array(data[table_source]['observationoffset'])[sorted_ids]\n",
    "            for _, entry in entry_mapping.iterrows():\n",
    "                entry_name_eicu = entry['ParamNameOrigin']\n",
    "                entry_uid = entry['TableUID']\n",
    "                sorted_vals = np.array(data[table_source][entry_name_eicu])[sorted_ids]\n",
    "#                 sorted_vals[pd.isnull(sorted_vals)] = np.nan\n",
    "                \n",
    "                data_table['Offset'] = np.append(data_table['Offset'], sorted_offset)\n",
    "                data_table['UID'] = np.append(data_table['UID'], [entry_uid]*len(sorted_offset))\n",
    "                data_table['Value'] = np.append(data_table['Value'], sorted_vals)\n",
    "                data_table['Unit'] = np.append(data_table['Unit'], [np.nan]*len(sorted_offset))\n",
    "                \n",
    "                if 'nan' in sorted_vals:\n",
    "                    print(entry_name_eicu)\n",
    "            check_table = data_table\n",
    "                \n",
    "        # intake & output\n",
    "        elif table_id ==3:\n",
    "            \n",
    "            entry_mapping = data_mapping[data_mapping['TableID']==table_id]\n",
    "            table_source = table_dict[table_id]\n",
    "            # intakeoutputoffset shared by [intaketotal, outtaketotal, dialysistotal, nettotal]\n",
    "            sorted_ids = np.argsort(data[table_source]['intakeoutputoffset'])\n",
    "            sorted_offset = np.array(data[table_source]['intakeoutputoffset'])[sorted_ids]\n",
    "            for _, entry in entry_mapping[entry_mapping['TableUID']<300005].iterrows():\n",
    "                entry_name_eicu = entry['ParamNameOrigin']\n",
    "                entry_uid = entry['TableUID']\n",
    "                sorted_vals = np.array(data[table_source][entry_name_eicu])[sorted_ids]\n",
    "#                 sorted_vals[pd.isnull(sorted_vals)] = np.nan\n",
    "                \n",
    "                data_table['Offset'] = np.append(data_table['Offset'], sorted_offset)\n",
    "                data_table['UID'] = np.append(data_table['UID'], [entry_uid]*len(sorted_offset))\n",
    "                data_table['Value'] = np.append(data_table['Value'], sorted_vals)\n",
    "                data_table['Unit'] = np.append(data_table['Unit'], [np.nan]*len(sorted_offset))\n",
    "\n",
    "            # other intake-output entries \n",
    "            for i, entry_name_eicu in enumerate(data[table_source]['celllabel']):\n",
    "                if entry_name_eicu in uid_dict:\n",
    "                    entry_uid = uid_dict[entry_name_eicu]\n",
    "                    entry_offset = data[table_source]['intakeoutputentryoffset'][i]\n",
    "                    entry_value = data[table_source]['cellvaluenumeric'][i]\n",
    "                    \n",
    "                    data_table['Offset'] = np.append(data_table['Offset'], entry_offset)\n",
    "                    data_table['UID'] = np.append(data_table['UID'], entry_uid)\n",
    "                    data_table['Value'] = np.append(data_table['Value'], entry_value)\n",
    "                    data_table['Unit'] = np.append(data_table['Unit'], np.nan)\n",
    "                \n",
    "            uid_mask = np.logical_and(\n",
    "                data_table['UID'] >= table_id * 1e5 + 5,\n",
    "                data_table['UID'] < (table_id + 1) * 1e5,\n",
    "            )\n",
    "            sorted_ids = np.argsort(data_table['Offset'][uid_mask])\n",
    "            for k in data_table:\n",
    "                data_table[k][uid_mask] = data_table[k][uid_mask][sorted_ids]\n",
    "                \n",
    "                \n",
    "        # lab\n",
    "        elif table_id == 4:\n",
    "            entry_mapping = data_mapping[data_mapping['TableID']==table_id]\n",
    "            table_source = table_dict[table_id]\n",
    "            \n",
    "            for i, entry_name_eicu in enumerate(data[table_source]['labname']):\n",
    "                if entry_name_eicu in uid_dict:\n",
    "                    entry_uid = uid_dict[entry_name_eicu]\n",
    "                    entry_offset = data[table_source]['labresultoffset'][i]\n",
    "                    entry_value = data[table_source]['labresulttext'][i]\n",
    "                    # convert lab data to float type\n",
    "                    entry_value = convert_lab_data_to_num(entry_value)\n",
    "                    \n",
    "                    data_table['Offset'] = np.append(data_table['Offset'], entry_offset)\n",
    "                    data_table['UID'] = np.append(data_table['UID'], entry_uid)\n",
    "                    data_table['Value'] = np.append(data_table['Value'], entry_value)\n",
    "                    data_table['Unit'] = np.append(data_table['Unit'], np.nan)\n",
    "                \n",
    "            uid_mask = np.logical_and(\n",
    "                data_table['UID'] >= table_id * 1e5,\n",
    "                data_table['UID'] < (table_id + 1) * 1e5,\n",
    "            )\n",
    "            sorted_ids = np.argsort(data_table['Offset'][uid_mask])\n",
    "            for k in data_table:\n",
    "                data_table[k][uid_mask] = data_table[k][uid_mask][sorted_ids]\n",
    "\n",
    "            \n",
    "            \n",
    "        # infusion drug\n",
    "        elif table_id == 5:\n",
    "            entry_mapping = data_mapping[data_mapping['TableID']==table_id]\n",
    "            table_source = table_dict[table_id]\n",
    "            \n",
    "            for i, entry_name_eicu in enumerate(data[table_source]['drugname']):\n",
    "                if entry_name_eicu in uid_dict:\n",
    "                    entry_uid = uid_dict[entry_name_eicu]\n",
    "                    entry_offset = data[table_source]['infusionoffset'][i]\n",
    "                    entry_value = data[table_source]['drugrate'][i]\n",
    "                    entry_weight = data[table_source]['patientweight'][i]\n",
    "                    if entry_value == '':\n",
    "                        continue\n",
    "                    # unify drugrate unit to: mg/min, units/min, ml/min\n",
    "                    entry_value, entry_unit = unify_drugrate_unit(entry_value, entry_name_eicu, entry_weight)\n",
    "\n",
    "                    data_table['Offset'] = np.append(data_table['Offset'], entry_offset)\n",
    "                    data_table['UID'] = np.append(data_table['UID'], entry_uid)\n",
    "                    data_table['Value'] = np.append(data_table['Value'], entry_value)\n",
    "                    data_table['Unit'] = np.append(data_table['Unit'], entry_unit)\n",
    "                    \n",
    "            uid_mask = np.logical_and(\n",
    "                data_table['UID'] >= table_id * 1e5,\n",
    "                data_table['UID'] < (table_id + 1) * 1e5,\n",
    "            )\n",
    "            sorted_ids = np.argsort(data_table['Offset'][uid_mask])\n",
    "            for k in data_table:\n",
    "                data_table[k][uid_mask] = data_table[k][uid_mask][sorted_ids]\n",
    "\n",
    "                \n",
    "        # nurse charting\n",
    "        elif table_id == 6:\n",
    "            entry_mapping = data_mapping[data_mapping['TableID']==table_id]\n",
    "            table_source = table_dict[table_id]\n",
    "            \n",
    "            for _, entry in entry_mapping.iterrows():\n",
    "                entry_name_eicu = entry['ParamNameOrigin']\n",
    "                entry_label_eicu = entry['ParamLabel']\n",
    "                entry_uid = entry['TableUID']\n",
    "\n",
    "                entry_sub_ids = select_entry_subset(data, table_source, 'nursingchartcelltypevalname', entry_name_eicu)[0]\n",
    "                entry_sub_ids = entry_sub_ids[np.in1d(\n",
    "                    entry_sub_ids,\n",
    "                    select_entry_subset(data, table_source, 'nursingchartcelltypevallabel', entry_label_eicu)[0],\n",
    "                )]\n",
    "                entry_offset = select_list_subset_with_index(data[table_source]['nursingchartentryoffset'], entry_sub_ids)\n",
    "                entry_value = select_list_subset_with_index(data[table_source]['nursingchartvalue'], entry_sub_ids)\n",
    "                \n",
    "                data_table['Offset'] = np.append(data_table['Offset'], entry_offset)\n",
    "                data_table['UID'] = np.append(data_table['UID'], [entry_uid]*len(entry_offset))\n",
    "                data_table['Value'] = np.append(data_table['Value'], entry_value)\n",
    "                data_table['Unit'] = np.append(data_table['Unit'], [np.nan]*len(entry_offset))\n",
    "                    \n",
    "                \n",
    "            uid_mask = np.logical_and(\n",
    "                data_table['UID'] >= table_id * 1e5,\n",
    "                data_table['UID'] < (table_id + 1) * 1e5,\n",
    "            )\n",
    "            sorted_ids = np.argsort(data_table['Offset'][uid_mask])\n",
    "            for k in data_table:\n",
    "                data_table[k][uid_mask] = data_table[k][uid_mask][sorted_ids]\n",
    "\n",
    "\n",
    "        # diagnosis\n",
    "        elif table_id == 7:\n",
    "            entry_mapping = data_mapping[data_mapping['TableID']==table_id]\n",
    "            table_source = table_dict[table_id]\n",
    "\n",
    "            entry_offset_all = data[table_source]['diagnosisoffset']\n",
    "            entry_name_all = data[table_source]['icd9code']\n",
    "            entry_value_all = data[table_source]['diagnosispriority']\n",
    "            \n",
    "            for offset, name, val in zip(entry_offset_all, entry_name_all, entry_value_all):\n",
    "                if name == '':\n",
    "                    continue\n",
    "                entry_uid = uid_dict[name]\n",
    "                val = DIAGNOSIS_PRIORITY_DICT[val]\n",
    "                data_table['Offset'] = np.append(data_table['Offset'], offset)\n",
    "                data_table['UID'] = np.append(data_table['UID'], entry_uid)\n",
    "                data_table['Value'] = np.append(data_table['Value'], val)\n",
    "                data_table['Unit'] = np.append(data_table['Unit'], np.nan)\n",
    "                \n",
    "            uid_mask = data_table['UID'] >= table_id * 1e5\n",
    "            sorted_ids = np.argsort(data_table['Offset'][uid_mask])\n",
    "            for k in data_table:\n",
    "                data_table[k][uid_mask] = data_table[k][uid_mask][sorted_ids]\n",
    "                \n",
    "    mask = np.logical_or(\n",
    "        np.logical_and(data_table['UID'] < 7e5, ~pd.isnull(data_table['Value'])),\n",
    "        data_table['UID'] >= 7e5\n",
    "    )\n",
    "    for k in data_table:\n",
    "        data_table[k] = data_table[k][mask]\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "    # save data to csv\n",
    "    df_info = pd.DataFrame(patient_info)\n",
    "    df_data = pd.DataFrame(data_table)\n",
    "    # delete duplicated diagnosis which have the same timestamp\n",
    "    df_data = df_data[df_data['UID']<7e5].append(df_data[df_data['UID']>7e5].drop_duplicates(keep='first'))\n",
    "    save_dir_info = 'processed_dataset/all/info/' \n",
    "    save_dir_data = 'processed_dataset/all/data/'\n",
    "    \n",
    "    save_csv(save_dir_info+str(pid)+'.csv', df_info)\n",
    "    save_csv(save_dir_data+str(pid)+'.csv', df_data)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}